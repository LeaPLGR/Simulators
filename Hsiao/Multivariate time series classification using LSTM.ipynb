{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fa6272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import cluster, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d91f808",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a44e7909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "y_train = pd.read_csv(\"truth2.csv\")\n",
    "x_train = pd.read_csv(\"data2.csv\")\n",
    "x_train.rename(columns={'time sample band g': 'time_g', 'time sample band r': 'time_r',\n",
    "                    'time sample band i': 'time_i','total flux + noise band g': 'tfnbg',\n",
    "                    'total flux + noise band r': 'tfnbr', 'total flux + noise band i': 'tfnbi',}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94f08e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>images</th>\n",
       "      <th>time origin</th>\n",
       "      <th>amplitude</th>\n",
       "      <th>time delays</th>\n",
       "      <th>magnifications</th>\n",
       "      <th>redshift</th>\n",
       "      <th>noise level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014196</td>\n",
       "      <td>2</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>[ 0.   11.58]</td>\n",
       "      <td>[1.46 1.01]</td>\n",
       "      <td>1.3563</td>\n",
       "      <td>0.1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000232</td>\n",
       "      <td>4</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>[ 0.   10.36 21.8  36.54]</td>\n",
       "      <td>[1.52 1.44 1.47 1.51]</td>\n",
       "      <td>1.9547</td>\n",
       "      <td>0.0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007104</td>\n",
       "      <td>2</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>[ 0.   11.86]</td>\n",
       "      <td>[1.07 1.57]</td>\n",
       "      <td>1.0272</td>\n",
       "      <td>0.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001133</td>\n",
       "      <td>2</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>[0.   5.51]</td>\n",
       "      <td>[1.06 1.04]</td>\n",
       "      <td>1.7510</td>\n",
       "      <td>0.0098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003329</td>\n",
       "      <td>1</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>0.0696</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1.49]</td>\n",
       "      <td>2.0615</td>\n",
       "      <td>0.0232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  images  time origin  amplitude                time delays  \\\n",
       "0  0.014196       2      55000.0     0.0445              [ 0.   11.58]   \n",
       "1  0.000232       4      55000.0     0.0330  [ 0.   10.36 21.8  36.54]   \n",
       "2  0.007104       2      55000.0     0.0494              [ 0.   11.86]   \n",
       "3  0.001133       2      55000.0     0.0330                [0.   5.51]   \n",
       "4  0.003329       1      55000.0     0.0696                        [0]   \n",
       "\n",
       "          magnifications  redshift  noise level  \n",
       "0            [1.46 1.01]    1.3563       0.1176  \n",
       "1  [1.52 1.44 1.47 1.51]    1.9547       0.0009  \n",
       "2            [1.07 1.57]    1.0272       0.0700  \n",
       "3            [1.06 1.04]    1.7510       0.0098  \n",
       "4                 [1.49]    2.0615       0.0232  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ecf50fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>images</th>\n",
       "      <th>time_g</th>\n",
       "      <th>tfnbg</th>\n",
       "      <th>time_r</th>\n",
       "      <th>tfnbr</th>\n",
       "      <th>time_i</th>\n",
       "      <th>tfnbi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014196</td>\n",
       "      <td>2</td>\n",
       "      <td>54956.2193</td>\n",
       "      <td>10570.401745</td>\n",
       "      <td>54955.2193</td>\n",
       "      <td>2704.516860</td>\n",
       "      <td>54958.6193</td>\n",
       "      <td>3299.079846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014196</td>\n",
       "      <td>2</td>\n",
       "      <td>54958.0193</td>\n",
       "      <td>-10693.304337</td>\n",
       "      <td>54956.0193</td>\n",
       "      <td>16453.482582</td>\n",
       "      <td>54963.8193</td>\n",
       "      <td>16040.613737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014196</td>\n",
       "      <td>2</td>\n",
       "      <td>54960.8193</td>\n",
       "      <td>-4770.734151</td>\n",
       "      <td>54958.8193</td>\n",
       "      <td>10039.765526</td>\n",
       "      <td>54969.0193</td>\n",
       "      <td>33172.352734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014196</td>\n",
       "      <td>2</td>\n",
       "      <td>54962.6193</td>\n",
       "      <td>7484.037437</td>\n",
       "      <td>54960.6193</td>\n",
       "      <td>16744.241350</td>\n",
       "      <td>54977.2193</td>\n",
       "      <td>47716.181787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014196</td>\n",
       "      <td>2</td>\n",
       "      <td>54963.4193</td>\n",
       "      <td>3437.042798</td>\n",
       "      <td>54961.4193</td>\n",
       "      <td>34833.539850</td>\n",
       "      <td>54981.4193</td>\n",
       "      <td>72337.577667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  images      time_g         tfnbg      time_r         tfnbr  \\\n",
       "0  0.014196       2  54956.2193  10570.401745  54955.2193   2704.516860   \n",
       "1  0.014196       2  54958.0193 -10693.304337  54956.0193  16453.482582   \n",
       "2  0.014196       2  54960.8193  -4770.734151  54958.8193  10039.765526   \n",
       "3  0.014196       2  54962.6193   7484.037437  54960.6193  16744.241350   \n",
       "4  0.014196       2  54963.4193   3437.042798  54961.4193  34833.539850   \n",
       "\n",
       "       time_i         tfnbi  \n",
       "0  54958.6193   3299.079846  \n",
       "1  54963.8193  16040.613737  \n",
       "2  54969.0193  33172.352734  \n",
       "3  54977.2193  47716.181787  \n",
       "4  54981.4193  72337.577667  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932abd87",
   "metadata": {},
   "source": [
    "## Checking balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b8d7aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.images.value_counts().plot(kind='bar')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e620646a",
   "metadata": {},
   "source": [
    "## Taking interesting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bf1f576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images', 'time_g', 'tfnbg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = x_train.columns.tolist()[1:4]\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed1106c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e74c566f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014196    91\n",
       "0.004569    91\n",
       "0.103519    91\n",
       "0.016212    91\n",
       "0.003302    91\n",
       "            ..\n",
       "0.056123    91\n",
       "0.139696    91\n",
       "0.017073    91\n",
       "0.001516    91\n",
       "0.021575    91\n",
       "Name: ID, Length: 9999, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.ID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a42cff54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train.ID.value_counts() ==91).sum() == len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd42b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = []\n",
    "for ide, group in x_train.groupby('ID'):\n",
    "    seq_features = group[feature_columns]\n",
    "    label = y_train[y_train.ID == ide].iloc[0]\n",
    "    \n",
    "    seq.append((seq_features, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "161e1291",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq, test_seq = train_test_split(seq, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37576647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7999, 2000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_seq), len(test_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3c7361",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69835ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagesDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, seq):\n",
    "        self.sequences = seq\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence, label = self.sequences[idx]\n",
    "        return dict(\n",
    "            sequence = torch.Tensor(sequence.to_numpy()), \n",
    "            label = torch.tensor(label[0]).to(dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c73d749",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagesDataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, train_sequence, test_sequence, batch_size):\n",
    "        super().__init__()\n",
    "        self.train_sequence = train_sequence\n",
    "        self.test_sequence = test_sequence\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        self.test_dataset = ImagesDataset(self.test_sequence)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            ImagesDataset(self.train_sequence),\n",
    "            batch_size = self.batch_size,\n",
    "            shuffle = False\n",
    "            )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size = self.batch_size,\n",
    "            shuffle = False\n",
    "            )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size = self.batch_size,\n",
    "            shuffle = False\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f774324c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8fbbbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_features, n_classes, n_hidden=256, n_layers=3):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size = n_features,\n",
    "            hidden_size = n_hidden,\n",
    "            num_layers = n_layers,\n",
    "            batch_first = True,\n",
    "            dropout = 0.75\n",
    "        )\n",
    "        self.classifier = nn.Linear(n_hidden, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.lstm.flatten_parameters()\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        \n",
    "        out = hidden[-1]\n",
    "        return self.classifier(out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30b077a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa5e9208350>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80c8ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SequenceModel(n_features = len(feature_columns), \n",
    "                        n_classes = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b54f633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceModel(\n",
      "  (lstm): LSTM(3, 256, num_layers=3, batch_first=True, dropout=0.75)\n",
      "  (classifier): Linear(in_features=256, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0e8a05",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64665724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "N_epochs = 250\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f39a654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader definition\n",
    "\n",
    "data_train = ImagesDataModule(train_seq, test_seq, batch_size)\n",
    "train_loader = data_train.train_dataloader()\n",
    "\n",
    "test_loader = ImagesDataset(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b432e9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5474c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer:\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0db1ea",
   "metadata": {},
   "source": [
    "## Network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bb5f5be",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wj/f1k4v84n75vfsjmdsxm0kfxh0000gn/T/ipykernel_1775/1511794437.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Forward Propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mlabels_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mlabels_val_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/wj/f1k4v84n75vfsjmdsxm0kfxh0000gn/T/ipykernel_1775/3444546659.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m             \u001b[0mis_batched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m             \u001b[0mbatch_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_batched\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "losses = []  \n",
    "val_losses = []\n",
    "i=0\n",
    "for epoch in range(N_epochs):  # Loop over epochs\n",
    "    running_loss = 0.0\n",
    "   \n",
    "    for features, labels in train_loader:        \n",
    "        \n",
    "        # Forward Propagation \n",
    "        labels_pred = model(features)\n",
    "        labels_val_pred = model(features_val)\n",
    "\n",
    "        # Loss computation\n",
    "        loss = loss_function(labels_pred,labels)\n",
    "\n",
    "        # Save loss for future analysis\n",
    "        losses.append(loss.item())\n",
    "        val_loss = loss_function(labels_val_pred,labels_val)\n",
    "        val_losses.append(val_loss.item())\n",
    "\n",
    "        # Erase previous gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute gradients (backpropagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # Weight update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    \n",
    "            print('[Epoque : %d, iteration: %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "        i+=1        \n",
    "   \n",
    "    print('Training done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcada1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f108b251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a92e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd72fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c339026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb914ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
