{
 "cells": [
  {
   "cell_type": "code",

   "execution_count": 1,

   "id": "69e45c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import cluster, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",

    "import torch.utils.data as data_utils\n",
    "import torch.nn.functional as Func\n",

    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 2,

   "id": "e1b534db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "f = pd.read_csv(\"data.csv\")\n",
    "f.rename(columns={'time sample band g': 'time_g', 'time sample band r': 'time_r',\n",
    "                    'time sample band i': 'time_i','total flux + noise band g': 'tfnbg',\n",
    "                    'total flux + noise band r': 'tfnbr', 'total flux + noise band i': 'tfnbi',}, inplace=True)"
   ]
  },
  {

   "cell_type": "markdown",
   "id": "bd3c89d6",
   "metadata": {},
   "source": [
    "def standard(dataset):\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range = (0, 1), copy=False)\n",
    "    #scaler = StandardScaler()\n",
    "    \n",
    "    df = 0\n",
    "    dfbis = 0\n",
    "    for ide, group in dataset.groupby('ID'):\n",
    "\n",
    "        a = dataset[dataset.ID == ide]\n",

    "        c = a[['ID', 'images']]\n",
    "        data = a[a.columns[2:]].copy()\n",
    "        t = ['time_g', 'time_r', 'time_i']\n",
    "        \n",
    "        data[['tfnbg', 'tfnbr', 'tfnbi']] = scaler.fit_transform(data[['tfnbg', 'tfnbr', 'tfnbi']])\n",
    "        data[t] = data[t]-np.min(data[t])\n",
    "\n",
    "        if ide == 0:\n",
    "            df = pd.concat([c, data], axis=1)\n",
    "        else:\n",
    "            dfbis = pd.concat([c, data], axis = 1)\n",
    "            df = pd.concat([df, dfbis])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 3,
   "id": "cfabebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f['images'] = f['images'].replace([1, 2, 3, 4], [0, 1, 1, 1])"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": 4,
   "id": "079732fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = f[:91*8000]\n",
    "val = f[91*8000:91*9000]\n",
    "test = f[91*9000:]"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": 5,
   "id": "48cc9e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359541\n",
      "368459\n",
      "45591\n",
      "45409\n"
     ]
    }
   ],
   "source": [
    "print((train['images']==0).sum())\n",
    "print((train['images']==1).sum())\n",
    "\n",
    "\n",
    "print((test['images']==0).sum())\n",
    "print((test['images']==1).sum())"

   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "id": "4dfcbe36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38fb0aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_dataset(f):\n",
    "        \n",
    "    scaler = MinMaxScaler(feature_range = (0, 1), copy=False)\n",
    "    #scaler = StandardScaler()\n",
    "\n",
    "    features_columns = f.columns.tolist()[2:]\n",
    "    T = []\n",
    "    F = []\n",
    "    \n",
    "    for ide, group in f.groupby('ID'):\n",
    "\n",
    "        a = f[f.ID == ide]\n",
    "        c = a[['ID', 'images']]\n",
    "        data = a.copy()\n",
    "        t = ['time_g', 'time_r', 'time_i']\n",
    "        \n",
    "        data[['tfnbg', 'tfnbr', 'tfnbi']] = scaler.fit_transform(data[['tfnbg', 'tfnbr', 'tfnbi']])\n",
    "        data[t] = data[t]-np.min(data[t])\n",
    "\n",
    "        T.append(a['images'].values[0])\n",
    "        F.append(torch.tensor(data[features_columns].T.values)[..., None])\n",
    "\n",
    "    \n",
    "    T = torch.tensor(T)\n",
    "    F = torch.cat(F, dim=-1)\n",
    "    print(F.shape)\n",
    "    return TensorDataset(F.T.double(), T.double())"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": 7,
   "id": "127a89a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 91, 8000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wj/f1k4v84n75vfsjmdsxm0kfxh0000gn/T/ipykernel_19852/4085115565.py:27: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  /Users/distiller/project/pytorch/aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  return TensorDataset(F.T.double(), T.double())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 91, 1000])\n",
      "torch.Size([6, 91, 1000])\n"
     ]
    }
   ],
   "source": [
    "TrainSet = dataframe_to_dataset(train)\n",
    "TestSet = dataframe_to_dataset(test)\n",
    "ValSet = dataframe_to_dataset(val)"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": 8,
   "id": "67cc393c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7ff00614e940>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainSet"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": 9,

   "id": "35b5c834",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceModel(nn.Module):\n",
    "    \n",

    "    def __init__(self, n_channels, n_classes, n_hidden=64):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        #self.lstm1 = nn.Conv1d(\n",
    "        #in_channels = n_features,\n",
    "        #out_channels = n_hidden,\n",
    "        #kernel_size = 5)\n",
    "        self.lstm1 = nn.LSTM(\n",
    "            input_size = n_channels,\n",
    "            hidden_size = n_hidden,\n",
    "            num_layers = 5) \n",
    "        \n",
    "        #self.lstm2 = nn.Conv1d(\n",
    "        #in_channels = n_hidden,\n",
    "        #out_channels = 128,\n",
    "        #kernel_size = 5)\n",
    "        \n",
    "        \n",
    "        self.c1 = nn.Linear(64*91, 512)\n",
    "        self.c2 = nn.Linear(512, n_classes-1)\n",
    "            \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, (ht, ct) = self.lstm1(x) \n",
    "        #x = Func.relu(self.lstm1(x))\n",
    "        #x = self.lstm1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x= self.c1(x)\n",
    "        pred = self.c2(x)\n",
    "        pred = torch.sigmoid(pred)\n",

    "        return pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 10,
   "id": "b03388b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff002b19df0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 11,
   "id": "ebc3c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SequenceModel(n_channels = 6, \n",
    "                        n_classes = 2)\n",
    "model = model.double()"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": 12,
   "id": "fcd4abac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceModel(\n",
      "  (lstm1): LSTM(6, 64, num_layers=5)\n",
      "  (c1): Linear(in_features=5824, out_features=512, bias=True)\n",
      "  (c2): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 13,
   "id": "d9ffa9ff",
   "metadata": {},
   "outputs": [],
   "source": [

    "TrainLoader = data_utils.DataLoader(TrainSet, batch_size = 16, shuffle = True)\n",
    "ValLoader = data_utils.DataLoader(ValSet, batch_size = 16, shuffle = False)\n",
    "TestLoader = data_utils.DataLoader(TestSet, batch_size = 16, shuffle = False)"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": 14,

   "id": "55cb8502",
   "metadata": {},
   "outputs": [],
   "source": [

    "loss_function = torch.nn.BCEWithLogitsLoss()"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": 15,

   "id": "de22a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 16,
   "id": "8534f1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- State_dict du model : ---\n",
      "lstm1.weight_ih_l0 \t torch.Size([256, 6])\n",
      "lstm1.weight_hh_l0 \t torch.Size([256, 64])\n",
      "lstm1.bias_ih_l0 \t torch.Size([256])\n",
      "lstm1.bias_hh_l0 \t torch.Size([256])\n",
      "lstm1.weight_ih_l1 \t torch.Size([256, 64])\n",
      "lstm1.weight_hh_l1 \t torch.Size([256, 64])\n",
      "lstm1.bias_ih_l1 \t torch.Size([256])\n",
      "lstm1.bias_hh_l1 \t torch.Size([256])\n",
      "lstm1.weight_ih_l2 \t torch.Size([256, 64])\n",
      "lstm1.weight_hh_l2 \t torch.Size([256, 64])\n",
      "lstm1.bias_ih_l2 \t torch.Size([256])\n",
      "lstm1.bias_hh_l2 \t torch.Size([256])\n",
      "lstm1.weight_ih_l3 \t torch.Size([256, 64])\n",
      "lstm1.weight_hh_l3 \t torch.Size([256, 64])\n",
      "lstm1.bias_ih_l3 \t torch.Size([256])\n",
      "lstm1.bias_hh_l3 \t torch.Size([256])\n",
      "lstm1.weight_ih_l4 \t torch.Size([256, 64])\n",
      "lstm1.weight_hh_l4 \t torch.Size([256, 64])\n",
      "lstm1.bias_ih_l4 \t torch.Size([256])\n",
      "lstm1.bias_hh_l4 \t torch.Size([256])\n",
      "c1.weight \t torch.Size([512, 5824])\n",
      "c1.bias \t torch.Size([512])\n",
      "c2.weight \t torch.Size([1, 512])\n",
      "c2.bias \t torch.Size([1])\n",
      "\n"
     ]
    }
   ],

   "source": [
    "print(\"--- State_dict du model : ---\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "print()"
   ]
  },
  {

   "cell_type": "code",
   "execution_count": 17,
   "id": "2bc4d2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done\n",
      "Training done\n",
      "Training done\n",
      "Training done\n",
      "Training done\n"
     ]
    }
   ],
   "source": [
    "losses = []  \n",
    "N_epochs = 5\n",
    "\n",
    "for epoch in range(N_epochs):  # Loop over epochs\n",
    "    \n",
    "    for features, label in TrainLoader:\n",
    "        #print(features.shape)\n",
    "        # Erase previous gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #print(features.shape)\n",
    "        labels_pred =[]\n",
    "        # Forward Propagation \n",
    "        labels_pred = model(features)  \n",
    "        #print(labels_pred.shape)\n",
    "        \n",
    "        #print(labels_pred)\n",
    "        #label = tensor(np.array(label[0].item()))   # for size 2 in output of the model\n",
    "        #label = torch.tensor([label[0].item()]).to(torch.float)\n",
    "        \n",
    "        \n",
    "        # Loss computation\n",
    "        loss = loss_function(labels_pred, label[..., None])\n",
    "        #val_loss = loss_function(labels_val_pred, labels_val)\n",

    "        # Save loss for future analysis\n",
    "        losses.append(loss.item())\n",
    "        #val_losses.append(val_loss)\n",
    "        \n",
    "\n",

    "\n",

    "        \n",
    "        # Compute gradients (backpropagation)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Weight update\n",

    "        optimizer.step()\n",

    "\n",
    "    print('Training done')"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 18,
   "id": "69d452de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7feff80af340>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display loss evolution\n",
    "fig, axes = plt.subplots(figsize=(8,6))\n",
    "axes.plot(losses,'r-',lw=2,label='Training loss function')\n",
    "#axes.plot(val_losses,'b-',lw=2,label='Validation loss function')\n",
    "axes.set_xlabel('N iterations',fontsize=18)\n",
    "axes.set_ylabel('Loss',fontsize=18)\n",
    "#plt.ylim([0, 1])\n",
    "plt.legend(loc='upper right',fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c33d0a19",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Double",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wj/f1k4v84n75vfsjmdsxm0kfxh0000gn/T/ipykernel_19852/3626120845.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Forward Propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mlabels_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/wj/f1k4v84n75vfsjmdsxm0kfxh0000gn/T/ipykernel_19852/113601052.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mht\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;31m#x = Func.relu(self.lstm1(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#x = self.lstm1(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    762\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    763\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Double"
     ]
    }
   ],

   "source": [
    "val_losses = []\n",
    "for epoch in range(N_epochs):  # Loop over epochs\n",
    "    running_loss = 0.0\n",
    "   \n",
    "    for features, labels in ValLoader:\n",
    "        \n",
    "        # Forward Propagation \n",
    "        labels_pred = model(features.float())\n",
    "        label = torch.tensor([labels[0].item()]).to(torch.float)\n",
    "\n",
    "        # Loss computation\n",
    "        loss = loss_function(labels_pred, label)\n",
    "\n",
    "        # Save loss for future analysis\n",
    "        val_losses.append(loss.item())\n",
    "        \n",
    "    print('Training done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "id": "bca08902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "def accuracy(model,dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # No need to compute gradients here\n",
    "    with torch.no_grad():\n",
    "        for features, labels in dataloader:\n",
    "            print(len(labels))\n",
    "            # Forward propagation to get predictions\n",
    "            pred = model(features.float()) \n",
    "            otherprob = 1 - pred.item()           \n",
    "            outputs = torch.tensor([[pred, otherprob]])\n",
    "            labels = torch.tensor([labels[0].item()]).to(torch.float)\n",
    "            print(labels)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            #print(total)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100.0 * correct / total       \n",
    "\n",
    "print('Accuracy : %.2f %%' % (accuracy(model,TestLoader)))   "

   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "id": "a17fd48b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "id": "b0d45b47",

   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
