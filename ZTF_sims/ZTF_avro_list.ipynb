{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing ZTF alerts stored as avro files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: AstropyDeprecationWarning: block_reduce was moved to the astropy.nddata.blocks module.  Please update your import statement. [astropy.nddata.utils]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('text', usetex=True)\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import os\n",
    "import io\n",
    "import gzip\n",
    "import tarfile\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from avro.datafile import DataFileReader, DataFileWriter\n",
    "from avro.io import DatumReader, DatumWriter\n",
    "import fastavro\n",
    "\n",
    "from astropy.time import Time\n",
    "from astropy.io import fits\n",
    "import astropy.units as u\n",
    "import aplpy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract compressed alerts archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "date = [\"20210831\", \"20210910\", \"20210914\", \"20210915\", \"20210916\", \"20210917\", \"20210918\", \"20210919\", \"20210920\",\n",
    "        \"20210921\", \"20210923\", \"20210926\", \"20210927\", \"20210928\", \"20210929\", \"20210930\", \"20211001\", \"20211002\",\n",
    "        \"20211003\", \"20211004\", \"20211007\", \"20211009\", \"20211010\", \"20211011\", \"20211013\", \"20211014\", \"20211015\"]\n",
    "'''\n",
    "date = [\"20211001\", \"20211002\",\n",
    "        \"20211003\", \"20211004\", \"20211007\", \"20211009\", \"20211010\", \"20211011\", \"20211013\", \"20211014\", \"20211015\"]\n",
    "\n",
    "output_dir = []\n",
    "for d in date:\n",
    "    output_dir.append(\"/Volumes/doogesh_HDPro/ZTF/ztf_public_\"+d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(root_dir):\n",
    "    for dir_name, subdir_list, file_list in os.walk(root_dir, followlinks=True):\n",
    "        for fname in file_list:\n",
    "            if fname.endswith('.avro'):\n",
    "                yield dir_name+'/'+fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_avro(fname):\n",
    "    with open(fname,'rb') as f:\n",
    "        freader = fastavro.reader(f)\n",
    "        # in principle there can be multiple packets per file\n",
    "        for packet in freader:\n",
    "            yield packet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dictionaries(root_dir):\n",
    "    for fname in find_files(root_dir):\n",
    "        for packet in open_avro(fname):\n",
    "            yield packet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply some filters/cuts to obtain high purity sample\n",
    "\n",
    "From ZTF Avro documentation: ZTF alert streams contain an nearly entirely unfiltered stream of all 5-sigma (only the most obvious artefacts are rejected). Depending on your science case, you may wish to improve the purity of your sample by filtering the data on the included attributes.\n",
    "\n",
    "Based on tests done at IPAC (F. Masci, priv. comm), the following filter delivers a relatively pure sample:\n",
    "\n",
    "* `rb >= 0.65`\n",
    "* `nbad = 0`\n",
    "* `fwhm <= 5`\n",
    "* `elong <= 1.2`\n",
    "* `abs(magdiff) <= 0.1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_alert_pure(packet):\n",
    "    pure = True\n",
    "    pure &= packet['candidate']['rb'] >= 0.65\n",
    "    pure &= packet['candidate']['nbad'] == 0\n",
    "    pure &= packet['candidate']['fwhm'] <= 5\n",
    "    pure &= packet['candidate']['elong'] <= 1.2\n",
    "    pure &= np.abs(packet['candidate']['magdiff']) <= 0.1\n",
    "    return pure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe we do not require this function\n",
    "def generate_programs(output_dir_):\n",
    "\n",
    "    print('{} has {} avro files'.format(output_dir_, len(list(find_files(output_dir_)))))\n",
    "\n",
    "    from collections import defaultdict\n",
    "    programs = defaultdict(int)\n",
    "    for packet in generate_dictionaries(output_dir_):\n",
    "        programs[packet['candidate']['programid']] += 1\n",
    "    print(programs)\n",
    "\n",
    "    return programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe we do not require this function\n",
    "def filter_programs(output_dir_):\n",
    "\n",
    "    programs = defaultdict(int)\n",
    "    for packet in filter(is_alert_pure,generate_dictionaries(output_dir_)):\n",
    "        programs[packet['candidate']['programid']] += 1\n",
    "    print(programs)\n",
    "\n",
    "    return programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For applications using lightcurves it's useful to have the data in a dataframe, but this construction is somewhat slower, so let's apply it after our initial filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe(packet):\n",
    "    dfc = pd.DataFrame(packet['candidate'], index=[0])\n",
    "    df_prv = pd.DataFrame(packet['prv_candidates'])\n",
    "    dflc = pd.concat([dfc,df_prv], ignore_index=True)\n",
    "    # we'll attach some metadata--not this may not be preserved after all operations\n",
    "    # https://stackoverflow.com/questions/14688306/adding-meta-information-metadata-to-pandas-dataframe\n",
    "    dflc.objectId = packet['objectId']\n",
    "    dflc.candid = packet['candid']\n",
    "    return dflc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the following cuts to select likely extragalactic transients:\n",
    "* the difference image detection should be positive;\n",
    "* if there is a PS1 source within 1.5\" of the source, it should have a star-galaxy score of < 0.5 (galaxy-like);\n",
    "* there should be at least two detections separated by more than 30 minutes;\n",
    "* there should be no known solar system object within 5\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_transient(dflc):\n",
    "    \n",
    "    candidate = dflc.loc[0]\n",
    "    \n",
    "    is_positive_sub = candidate['isdiffpos'] == 't'\n",
    "    \n",
    "    if (candidate['distpsnr1'] is None) or (candidate['distpsnr1'] > 1.5):\n",
    "        no_pointsource_counterpart = True\n",
    "    else:\n",
    "        if candidate['sgscore1'] < 0.5:\n",
    "            no_pointsource_counterpart = True\n",
    "        else:\n",
    "            no_pointsource_counterpart = False\n",
    "            \n",
    "    where_detected = (dflc['isdiffpos'] == 't') # nondetections will be None\n",
    "    if np.sum(where_detected) >= 2:\n",
    "        detection_times = dflc.loc[where_detected,'jd'].values\n",
    "        dt = np.diff(detection_times)\n",
    "        not_moving = np.max(dt) >= (30*u.minute).to(u.day).value\n",
    "    else:\n",
    "        not_moving = False\n",
    "    \n",
    "    no_ssobject = (candidate['ssdistnr'] is None) or (candidate['ssdistnr'] < 0) or (candidate['ssdistnr'] > 5)\n",
    "    \n",
    "    return is_positive_sub and no_pointsource_counterpart and not_moving and no_ssobject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/ZTF_selection_temp.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m transient_selection_list \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/ZTF_selection_temp.npz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransient_selection_list\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/npyio.py:407\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    405\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 407\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    408\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/ZTF_selection_temp.npz'"
     ]
    }
   ],
   "source": [
    "transient_selection_list = np.load(\"data/ZTF_selection_temp.npz\")['transient_selection_list'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transient_selection_list = []\n",
    "\n",
    "pbar = tqdm(total=len(output_dir))\n",
    "\n",
    "for out_dir in output_dir:\n",
    "    for packet in filter(is_alert_pure,generate_dictionaries(out_dir)):\n",
    "        dflc = make_dataframe(packet)\n",
    "        if is_transient(dflc):\n",
    "            #print(packet['objectId'])\n",
    "            if packet['objectId'] not in transient_selection_list:\n",
    "                transient_selection_list.append(packet['objectId'])\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transient_selection_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"data/ZTF_selection.npz\", transient_selection_list=transient_selection_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
